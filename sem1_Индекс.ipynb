{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 1 Индекс\n",
    "\n",
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### чтение файла \n",
    "- конструкция __with open__ (recommended)\n",
    "- конструкция __open + close__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'fpath.txt'\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, 'r') as f:  \n",
    "    text = f.read() \n",
    "\n",
    "#по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "#по строкам, без \\n   \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.read().splitlines() \n",
    "    \n",
    "#not reccomended  \n",
    "file = open(txt_fpath, 'r')  \n",
    "text = file.read()    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### работа с файлами и папками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path  \n",
    "путь до файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath('fpath.txt'))\n",
    "\n",
    "# возвращает имя файла / папки по полному пути до него\n",
    "print(os.path.basename('/your/path/to/folder/with/fpath.txt'))\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists('your/path/to/any/folder/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "os.listdir(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем пути абсолютными, чтобы наш код не зависел от того, где лежит этот файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir) if not '.DS_Store' in fpath]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __os.walk__ возвращает генератор, это значит, что получить его элементы можно только проитерировавшись по нему  \n",
    "но его легко можно превратить в list и увидеть все его значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.walk(main_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__: \n",
    "получите обратный индекс для коллекция документов.    \n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия - один документ.\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/k_M7n63A3adGSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы:   \n",
    "    1. получить коллекцию документов\n",
    "    2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку\n",
    "    3. получить матрицу терм-документ, написать функцию поиска по ней\n",
    "    4. получить обратный индекс в виде словаря, где ключ - нормализованное слово, \n",
    "    значение - список файлов, в которых это слово встречается\n",
    "    5. вывести кусочек индекса в виде таблицы \n",
    "    6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Friends/wedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, старайтесь этого избегать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. получить коллекцию документов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = './Friends/'\n",
    "files_list = []\n",
    "\n",
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "### _check : в коллекции должно быть 165 файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        if name != '.DS_Store':\n",
    "            files_list.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'[\\s]{2,}', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = clean_data(text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "    \n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        f = f.read()\n",
    "    \n",
    "    normalized = normalize(f)\n",
    "    res_texts.append(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. получить матрицу терм-документ, написать функцию поиска по ней**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### постройте матрицу терм-документ\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(res_texts)\n",
    "term_doc_matrix = pd.DataFrame(X.toarray(), columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### напишите функцию булева поиска по построенной матрице\n",
    "def boolean_search() -> list:\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the term-document matrix\n",
    "    :return: list of first 5 relevant documents\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "\n",
    "#запросы \n",
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джои & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джои) & Росс', \n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джои & (НЕ Росс)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. получить обратный индекс в виде словаря, где ключ - нормализованное слово, \n",
    "значение - список файлов, в которых это слово встречается**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index() -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim() -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    return \n",
    "\n",
    "\n",
    "def get_search_result() -> list:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
